---
model:
    name: QLearn
    parameters:
        alpha: [0, 1]
        beta: [0, 30]
    number_actions: 6
    number_cues: 1
    action_codes: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}
    stimulus_shaper_name: StimulusProbSelectDirect
    reward_shaper_name: RewardProbSelectDirect
    decision_function_name: weightProb
    task_responses: ['A', 'B', 'C', 'D', 'E', 'F']

data:
    path: './tests/test_sim/Pickle/'
    format: 'pkl'
    valid_files: 'QLearn_modelData_sim-'
    name: 'simID'
    choices: 'Decisions'
    rewards: 'Rewards'
    stimuli: ~ # "stimCues" # could be a list
    action_options: ['ValidActions_0', 'ValidActions_1']
    extra_processing: |
        def data_processing(dat):
            for i, d in enumerate(dat['ValidActions']):
                dat['ValidActions_{}'.format(i)] = d
            return dat

fitting:
    method: Evolutionary
    measures:
        main: '-loge'
        extras:
            - '-2log'
            - 'BIC'
            - 'r2'
            - 'bayesFactor'
            - 'BIC2norm'
        parameters:
            numParams: 2
            number_actions: 6
            qualityThreshold: 20
            randActProb: 0.5
    trial_subset: 'all'
    fitting_variable: 'ActionProb'


saving:
    name: 'qLearn_probSelect_fromSim'
    save_fitting_progress: True
    pickle: False
    bound_cost_function: ~

