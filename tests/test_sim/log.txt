20-06-27 14:41 Setup        INFO     2020-6-27
20-06-27 14:41 Setup        INFO     Log initialised
20-06-27 14:41 Setup        INFO     The log you are reading was written to test_sim/log.txt
20-06-27 14:41 Framework    INFO     Beginning task labelled: qLearn_probSelectSimSet
20-06-27 14:41 Simulation   INFO     Simulation 0 contains the task ProbSelect: reward_probability = 0.7, action_reward_probabilities = {'A': 0.8, 'B': 0.2, 'C': 0.7, 'D': 0.3, 'E': 0.6, 'F': 0.4}, learning_action_pairs = [('A', 'B'), ('C', 'D'), ('E', 'F')], learning_length = 100, reward_size = 1, task_length = 150, number_actions = 6, valid_actions = ['A', 'B', 'C', 'D', 'E', 'F'], action_sequence = [array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), ['D', 'A'], ['A', 'C'], ['E', 'C'], ['A', 'F'], ['B', 'E'], ['B', 'E'], ['C', 'E'], ['E', 'A'], ['A', 'E'], ['B', 'C'], ['E', 'A'], ['C', 'E'], ['E', 'C'], ['F', 'D'], ['C', 'F'], ['B', 'C'], ['F', 'D'], ['B', 'E'], ['A', 'D'], ['B', 'C'], ['E', 'D'], ['D', 'E'], ['A', 'E'], ['C', 'F'], ['D', 'B'], ['B', 'E'], ['E', 'D'], ['D', 'F'], ['B', 'D'], ['D', 'B'], ['F', 'D'], ['C', 'F'], ['F', 'A'], ['F', 'C'], ['C', 'A'], ['F', 'B'], ['D', 'E'], ['E', 'A'], ['D', 'F'], ['C', 'B'], ['C', 'A'], ['A', 'F'], ['E', 'B'], ['C', 'E'], ['B', 'F'], ['B', 'D'], ['D', 'E'], ['F', 'A'], ['D', 'A'], ['F', 'C']]. The model used is QLearn: number_actions = 6, number_cues = 1, number_critics = 6, prior = array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,
       0.16666667]), non_action = 'None', action_code = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}, stimulus_shaper = 'tasks.probSelect.StimulusProbSelectDirect with ', reward_shaper = 'tasks.probSelect.RewardProbSelectDirect with ', decision_function = "discrete.weightProb with task_responses : 'A', 'B', 'C', 'D', 'E', 'F'", alpha = 0.3, beta = 0.5, expectation = array([[0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5]]).
20-06-27 14:41 Simulation   INFO     Simulation 1 contains the task ProbSelect: reward_probability = 0.7, action_reward_probabilities = {'A': 0.8, 'B': 0.2, 'C': 0.7, 'D': 0.3, 'E': 0.6, 'F': 0.4}, learning_action_pairs = [('A', 'B'), ('C', 'D'), ('E', 'F')], learning_length = 100, reward_size = 1, task_length = 150, number_actions = 6, valid_actions = ['A', 'B', 'C', 'D', 'E', 'F'], action_sequence = [array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), ['C', 'F'], ['B', 'D'], ['F', 'B'], ['E', 'A'], ['B', 'D'], ['B', 'E'], ['C', 'B'], ['A', 'E'], ['C', 'F'], ['B', 'F'], ['F', 'D'], ['B', 'C'], ['E', 'C'], ['F', 'A'], ['C', 'E'], ['D', 'E'], ['C', 'F'], ['F', 'C'], ['F', 'B'], ['D', 'F'], ['D', 'B'], ['D', 'F'], ['D', 'F'], ['F', 'A'], ['E', 'B'], ['E', 'D'], ['F', 'C'], ['E', 'A'], ['A', 'D'], ['A', 'E'], ['D', 'B'], ['F', 'C'], ['F', 'A'], ['F', 'B'], ['B', 'D'], ['B', 'C'], ['F', 'D'], ['E', 'D'], ['A', 'C'], ['F', 'C'], ['A', 'C'], ['C', 'F'], ['D', 'E'], ['F', 'D'], ['A', 'F'], ['A', 'E'], ['D', 'A'], ['D', 'B'], ['A', 'F'], ['B', 'E']]. The model used is QLearn: number_actions = 6, number_cues = 1, number_critics = 6, prior = array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,
       0.16666667]), non_action = 'None', action_code = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}, stimulus_shaper = 'tasks.probSelect.StimulusProbSelectDirect with ', reward_shaper = 'tasks.probSelect.RewardProbSelectDirect with ', decision_function = "discrete.weightProb with task_responses : 'A', 'B', 'C', 'D', 'E', 'F'", alpha = 0.7, beta = 0.5, expectation = array([[0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5]]).
20-06-27 14:41 Simulation   INFO     Simulation 2 contains the task ProbSelect: reward_probability = 0.7, action_reward_probabilities = {'A': 0.8, 'B': 0.2, 'C': 0.7, 'D': 0.3, 'E': 0.6, 'F': 0.4}, learning_action_pairs = [('A', 'B'), ('C', 'D'), ('E', 'F')], learning_length = 100, reward_size = 1, task_length = 150, number_actions = 6, valid_actions = ['A', 'B', 'C', 'D', 'E', 'F'], action_sequence = [array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), ['D', 'F'], ['B', 'D'], ['B', 'F'], ['F', 'B'], ['C', 'F'], ['E', 'C'], ['D', 'E'], ['E', 'D'], ['C', 'B'], ['A', 'E'], ['F', 'A'], ['D', 'E'], ['B', 'C'], ['A', 'E'], ['C', 'B'], ['A', 'D'], ['E', 'B'], ['D', 'F'], ['A', 'D'], ['D', 'A'], ['E', 'B'], ['C', 'E'], ['F', 'D'], ['D', 'E'], ['C', 'A'], ['C', 'E'], ['D', 'A'], ['B', 'F'], ['C', 'B'], ['D', 'A'], ['D', 'F'], ['A', 'C'], ['C', 'E'], ['A', 'C'], ['F', 'A'], ['D', 'E'], ['D', 'A'], ['F', 'A'], ['B', 'F'], ['D', 'E'], ['E', 'A'], ['D', 'B'], ['D', 'F'], ['A', 'D'], ['A', 'D'], ['C', 'F'], ['F', 'D'], ['B', 'E'], ['C', 'E'], ['A', 'F']]. The model used is QLearn: number_actions = 6, number_cues = 1, number_critics = 6, prior = array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,
       0.16666667]), non_action = 'None', action_code = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}, stimulus_shaper = 'tasks.probSelect.StimulusProbSelectDirect with ', reward_shaper = 'tasks.probSelect.RewardProbSelectDirect with ', decision_function = "discrete.weightProb with task_responses : 'A', 'B', 'C', 'D', 'E', 'F'", alpha = 0.3, beta = 2.0, expectation = array([[0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5]]).
20-06-27 14:41 Simulation   INFO     Simulation 3 contains the task ProbSelect: reward_probability = 0.7, action_reward_probabilities = {'A': 0.8, 'B': 0.2, 'C': 0.7, 'D': 0.3, 'E': 0.6, 'F': 0.4}, learning_action_pairs = [('A', 'B'), ('C', 'D'), ('E', 'F')], learning_length = 100, reward_size = 1, task_length = 150, number_actions = 6, valid_actions = ['A', 'B', 'C', 'D', 'E', 'F'], action_sequence = [array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), ['A', 'D'], ['F', 'D'], ['D', 'A'], ['B', 'E'], ['B', 'E'], ['F', 'D'], ['D', 'F'], ['C', 'F'], ['A', 'F'], ['D', 'F'], ['B', 'C'], ['C', 'B'], ['A', 'D'], ['B', 'E'], ['D', 'F'], ['E', 'D'], ['B', 'E'], ['A', 'F'], ['F', 'D'], ['F', 'D'], ['E', 'A'], ['E', 'B'], ['E', 'C'], ['A', 'F'], ['D', 'E'], ['C', 'E'], ['A', 'F'], ['E', 'C'], ['F', 'D'], ['A', 'F'], ['C', 'F'], ['F', 'B'], ['B', 'F'], ['F', 'A'], ['F', 'A'], ['F', 'C'], ['A', 'C'], ['D', 'B'], ['F', 'D'], ['D', 'A'], ['B', 'D'], ['A', 'D'], ['E', 'A'], ['A', 'F'], ['E', 'D'], ['A', 'D'], ['D', 'B'], ['A', 'E'], ['E', 'B'], ['E', 'B']]. The model used is QLearn: number_actions = 6, number_cues = 1, number_critics = 6, prior = array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,
       0.16666667]), non_action = 'None', action_code = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}, stimulus_shaper = 'tasks.probSelect.StimulusProbSelectDirect with ', reward_shaper = 'tasks.probSelect.RewardProbSelectDirect with ', decision_function = "discrete.weightProb with task_responses : 'A', 'B', 'C', 'D', 'E', 'F'", alpha = 0.7, beta = 2.0, expectation = array([[0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5]]).
20-06-27 14:41 Simulation   INFO     Simulation 4 contains the task ProbSelect: reward_probability = 0.7, action_reward_probabilities = {'A': 0.8, 'B': 0.2, 'C': 0.7, 'D': 0.3, 'E': 0.6, 'F': 0.4}, learning_action_pairs = [('A', 'B'), ('C', 'D'), ('E', 'F')], learning_length = 100, reward_size = 1, task_length = 150, number_actions = 6, valid_actions = ['A', 'B', 'C', 'D', 'E', 'F'], action_sequence = [array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), ['B', 'D'], ['A', 'E'], ['A', 'C'], ['E', 'C'], ['A', 'E'], ['D', 'B'], ['F', 'C'], ['F', 'D'], ['D', 'B'], ['D', 'E'], ['E', 'A'], ['B', 'C'], ['A', 'C'], ['D', 'E'], ['A', 'C'], ['A', 'F'], ['C', 'E'], ['F', 'B'], ['B', 'C'], ['E', 'A'], ['E', 'C'], ['D', 'F'], ['C', 'A'], ['A', 'C'], ['F', 'C'], ['B', 'E'], ['B', 'D'], ['D', 'A'], ['A', 'E'], ['A', 'D'], ['D', 'B'], ['A', 'C'], ['D', 'F'], ['F', 'C'], ['B', 'C'], ['D', 'F'], ['F', 'B'], ['C', 'B'], ['A', 'E'], ['F', 'C'], ['B', 'E'], ['D', 'E'], ['C', 'A'], ['A', 'C'], ['A', 'C'], ['B', 'D'], ['A', 'F'], ['F', 'C'], ['C', 'E'], ['A', 'C']]. The model used is QLearn: number_actions = 6, number_cues = 1, number_critics = 6, prior = array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,
       0.16666667]), non_action = 'None', action_code = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}, stimulus_shaper = 'tasks.probSelect.StimulusProbSelectDirect with ', reward_shaper = 'tasks.probSelect.RewardProbSelectDirect with ', decision_function = "discrete.weightProb with task_responses : 'A', 'B', 'C', 'D', 'E', 'F'", alpha = 0.3, beta = 16.0, expectation = array([[0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5]]).
20-06-27 14:41 Simulation   INFO     Simulation 5 contains the task ProbSelect: reward_probability = 0.7, action_reward_probabilities = {'A': 0.8, 'B': 0.2, 'C': 0.7, 'D': 0.3, 'E': 0.6, 'F': 0.4}, learning_action_pairs = [('A', 'B'), ('C', 'D'), ('E', 'F')], learning_length = 100, reward_size = 1, task_length = 150, number_actions = 6, valid_actions = ['A', 'B', 'C', 'D', 'E', 'F'], action_sequence = [array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['C', 'D'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), array(['A', 'B'], dtype='<U1'), array(['E', 'F'], dtype='<U1'), ['B', 'E'], ['B', 'E'], ['E', 'B'], ['D', 'E'], ['A', 'F'], ['A', 'D'], ['A', 'E'], ['A', 'C'], ['A', 'E'], ['D', 'E'], ['E', 'B'], ['E', 'A'], ['B', 'E'], ['E', 'D'], ['F', 'D'], ['F', 'C'], ['F', 'B'], ['C', 'E'], ['D', 'B'], ['D', 'E'], ['F', 'C'], ['A', 'E'], ['A', 'D'], ['E', 'C'], ['C', 'E'], ['B', 'C'], ['D', 'F'], ['F', 'B'], ['A', 'D'], ['D', 'A'], ['B', 'F'], ['C', 'E'], ['D', 'F'], ['F', 'D'], ['B', 'C'], ['B', 'D'], ['F', 'A'], ['E', 'C'], ['F', 'B'], ['F', 'B'], ['C', 'A'], ['B', 'E'], ['D', 'B'], ['F', 'A'], ['A', 'D'], ['A', 'F'], ['E', 'B'], ['B', 'D'], ['E', 'C'], ['E', 'C']]. The model used is QLearn: number_actions = 6, number_cues = 1, number_critics = 6, prior = array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,
       0.16666667]), non_action = 'None', action_code = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}, stimulus_shaper = 'tasks.probSelect.StimulusProbSelectDirect with ', reward_shaper = 'tasks.probSelect.RewardProbSelectDirect with ', decision_function = "discrete.weightProb with task_responses : 'A', 'B', 'C', 'D', 'E', 'F'", alpha = 0.7, beta = 16.0, expectation = array([[0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5],
       [0.5]]).
20-06-27 14:41 Setup        INFO     Shutting down program
